#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split


# Data Acquisition

# In[2]:


df = pd.read_csv("MalwarePEfeatures.csv")    #import file


# In[3]:


print("Total no. of rows:",df.shape[0])
print("Total no. of columns:",df.shape[1])


# In[4]:


df.head()     #first 5 rows of the dataset


# Data Pre-processing

# In[5]:


# dropping features with zero variance
x = df.drop(['Name','Malware',  'e_magic', 'SectionMaxRawsize', 'SectionMaxVirtualsize', 'SectionMinPhysical', 'SectionMinVirtual', 'SectionMinPointerData', 'SectionMainChar' ], axis=1)


# In[6]:


print("Total no. of columns after dropping:",x.shape[1])


# In[7]:


print("Duplicate records")
x.duplicated(keep='first')


# In[8]:


x.fillna('-')
print("Number of empty cells:",x.isnull().sum().sum()) 


# In[9]:


#splitting dataset in a ratio of 70:30
xTrain, xTest, yTrain, yTest = train_test_split(x, df['Malware'], test_size = 0.3, random_state = 0)


# In[10]:


print("Rows in Train set:", xTrain.shape[0])
print("Rows in Test set:", xTest.shape[0])


# In[11]:


def standardizeDataset(xTrain, xTest):
    scaler = StandardScaler()
    xTrain = scaler.fit_transform(xTrain)
    xTest = scaler.transform(xTest)

    pca = PCA(n_components = 0.55)  
    xTrainStd = pca.fit_transform(xTrain)
    xTestStd = pca.transform(xTest)
    
    return xTrainStd, xTestStd


# In[12]:


# Applying PCA to scale down the features(reduce number of columns)
xTrainStd, xTestStd = standardizeDataset(xTrain, xTest)


# In[13]:


print("Columns before PCA")
print(xTrain.shape[1])
print("\nColumns after PCA")
print(xTrainStd.shape[1])


# In[14]:


def Accuracy(classifier, expected_labels, predicted_labels):
    accuracy = classifier.score(xTestStd, expected_labels)
    print("Accuracy:",accuracy)
    metrics.plot_confusion_matrix(classifier, xTestStd, yTest, display_labels=["benign", "malware"])
    plt.show()
    print(metrics.classification_report(expected_labels, predicted_labels))
    print("Confusion Matrix")
    print(metrics.confusion_matrix(expected_labels, predicted_labels))


# In[15]:


def AUC_ROC_curve(expected_labels, predicted_labels, classifier, probability):
    
    roc_auc = metrics.roc_auc_score(expected_labels, probability)
    print('Area Under the Curve: %.2f' % roc_auc)
    fpr, tpr, thresholds = metrics.roc_curve(expected_labels, probability)
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic(' + classifier + ')')
    plt.legend(loc="lower right")
    plt.show()


# In[16]:


def NaiveBayes():
    classifier = GaussianNB()
    classifier.fit(xTrainStd, yTrain)
    predicted_labels = classifier.predict(xTestStd)
    probability = classifier.predict_proba(xTestStd)
    probability = probability[:, 1]
    expected_labels = yTest
    Accuracy(classifier, expected_labels, predicted_labels)
    AUC_ROC_curve(expected_labels, predicted_labels, "Naive Bayes", probability)
    expected_labels = list(expected_labels)
    print("Expected - Predicted")
    for i in range(20):
        print(expected_labels[i], "-", predicted_labels[i])


# In[17]:


def KNN():
    classifier = KNeighborsClassifier()
    classifier.fit(xTrainStd, yTrain)
    predicted_labels = classifier.predict(xTestStd)
    probability = classifier.predict_proba(xTestStd)
    probability = probability[:, 1]
    expected_labels = yTest
    Accuracy(classifier, expected_labels, predicted_labels)
    AUC_ROC_curve(expected_labels, predicted_labels, "kNN", probability)
    expected_labels = list(expected_labels)
    print("Expected - Predicted")
    for i in range(20):
        print(expected_labels[i], "-", predicted_labels[i])


# In[18]:


def DecisionTree():
    classifier = DecisionTreeClassifier()
    classifier.fit(xTrainStd, yTrain)
    predicted_labels = classifier.predict(xTestStd)
    probability = classifier.predict_proba(xTestStd)
    probability = probability[:, 1]
    expected_labels = yTest
    Accuracy(classifier, expected_labels, predicted_labels)
    AUC_ROC_curve(expected_labels, predicted_labels, "Decision Tree", probability)
    expected_labels = list(expected_labels)
    print("Expected - Predicted")
    for i in range(20):
        print(expected_labels[i], "-", predicted_labels[i])


# In[19]:


def SVM():
    classifier = SVC(probability=True)
    classifier.fit(xTrainStd, yTrain)
    predicted_labels = classifier.predict(xTestStd)
    probability = classifier.predict_proba(xTestStd)
    probability = probability[:, 1]
    expected_labels = yTest
    Accuracy(classifier, expected_labels, predicted_labels)
    AUC_ROC_curve(expected_labels, predicted_labels, "SVM", probability)
    expected_labels = list(expected_labels)
    print("Expected - Predicted")
    for i in range(20):
        print(expected_labels[i], "-", predicted_labels[i])


# In[20]:


def RandomForest():
    classifier = RandomForestClassifier()
    classifier.fit(xTrainStd, yTrain)
    predicted_labels = classifier.predict(xTestStd)
    probability = classifier.predict_proba(xTestStd)
    probability = probability[:, 1]
    expected_labels = yTest
    Accuracy(classifier, expected_labels, predicted_labels)
    AUC_ROC_curve(expected_labels, predicted_labels, "Random Forest", probability)
    expected_labels = list(expected_labels)
    print("Expected - Predicted")
    for i in range(20):
        print(expected_labels[i], "-", predicted_labels[i])


# No. of malware files: 4386
# No. of benign files: 1498

# ML Classifiers

# In[21]:


NaiveBayes()


# In[22]:


KNN()


# In[23]:


SVM()


# In[24]:


DecisionTree()


# In[25]:


RandomForest()


# In[27]:


import joblib
from sklearn.pipeline import make_pipeline

pipeline1 = make_pipeline(StandardScaler(), PCA(n_components = 0.55), GaussianNB())
pipeline2 = make_pipeline(StandardScaler(), PCA(n_components = 0.55), DecisionTreeClassifier())
pipeline3 = make_pipeline(StandardScaler(), PCA(n_components = 0.55), KNeighborsClassifier())
pipeline4 = make_pipeline(StandardScaler(), PCA(n_components = 0.55), SVC())
pipeline5 = make_pipeline(StandardScaler(), PCA(n_components = 0.55), RandomForestClassifier())

pipelines = [pipeline1, pipeline2, pipeline3, pipeline4, pipeline5]
for i in range(len(pipelines)):
    pipelines[i].fit(xTrain, yTrain)
    joblib.dump(pipelines[i],"C:/Users/kriti/github/ML-React-App-Template/service/pipeline" + str(i + 1) +".joblib")

